<!DOCTYPE html>
<html>
	<head>
		<meta name="description" content="Home page of Zhe Hou">
		<meta name="author" content="Zhe Hou">
		<meta name="keywords" content="Zhe Hou,Research,Computer Science,Logic,Formal Methods,AI">

		<title>Zhe Hou's Home Page</title>
		<!-- link to main stylesheet -->
		<link rel="stylesheet" type="text/css" href="/css/main.css">
	</head>
	<body>
		<nav>
    		<ul>
        		<li><a href="/">Home</a></li>
	        	<li><a href="/papers">Publications</a></li>
				<li><a href="/apps">Applications</a></li>  
				<li><a href="/acts/">Activities</a></li>      		
    		</ul>
		</nav>
		<div class="container">
    		<div class="blurb">
        		<h1>Zhe Hou's Home Page</h1>
        		
        		<p>Research Fellow at Institute for Integrated and Intelligent Systems, Griffith Univerity<br/>
        		Address: N34, 170 Kessels Rd, Nathan, 4111, Australia<br/>
        		Email: z.hou at griffith.edu.au<br/>
        		Tel: +61 7 3735 3765</p>

        		<!-- <p>Zhe Hou is currently a research fellow at Griffith University. He is working on integrating automated reasoning techniques into machine learning, planning and goal reasoning, which will be applied to trusted autonomous systems.</p> -->

				<h2>Overview</h2>

				<p>Zhe Hou obtained PhD from The Australian National University. He has developed various automated reasoning techniques and tools for separation logic -- a logic for reasoning about computer programs with pointers and other mutable data structures. In 2015 he joined Nanyang Technological University to undertake the project "Securify", which was about verifying the correctness and security of computer systems. He was the main researcher responsible for developing formal models of the SPARCv8 instruction set architecture and TSO weak memory model, and verifying information-flow security. He joined Griffith University in 2017 on a project to develop trusted autonomous systems in collaboration with Australia Defense Science and Technology Group.</p>
				
				<h2>Research Interests</h2>

				<p>Automated reasoning: separation logic, theorem proving, model checking.<br/>
				Formal methods: program verification, weak memory model, information-flow security.<br/>
				Autonomous systems: planning, goal reasoning.<br/>
				Machine learning: prediction, classification, large scale data analysis.<br/>
					<!-- <li><a href="/blog">Blog</a></li> -->
				</p>
						
				<h2>Spare Time</h2>
				Zhe has a garage project in which he and his friends integrate the state-of-the-art automated reasoning techniques into an efficient machine learning tool called <a href="https://www.depintel.com/silas/">Silas</a> in order to achieve explainable and verifiable machine learning. The result is a Silas extension that is able to extract the core decision-making of machine learning models and formally verify that the machine learning models are correct with respect to certain user-specified criteria.

    		</div><!-- /.blurb -->
		</div><!-- /.container -->
		<!-- <footer>
    		<ul>
        		<li><a href="mailto:z.hou@griffith.edu.au">email</a></li>
        		
			</ul>
		</footer> -->
	</body>
</html>